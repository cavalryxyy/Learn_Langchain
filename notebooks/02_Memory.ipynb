{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afd1a66b",
   "metadata": {},
   "source": [
    "## memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4388d8",
   "metadata": {},
   "source": [
    "### default memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b4eb6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding connection: connected\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from langchain_utils import get_llm, get_conversation_chain, get_memory, MODEL_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a483c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the configured LLM\n",
    "llm = get_llm()\n",
    "# Get the conversation chain with memory\n",
    "conv = get_conversation_chain()\n",
    "\n",
    "# Get just the memory\n",
    "memory = get_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b70fba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4aa99f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm here and ready to help. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20cbe5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'completion_tokens': 17,\n",
       " 'prompt_tokens': 13,\n",
       " 'total_tokens': 30,\n",
       " 'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "  'audio_tokens': 0,\n",
       "  'reasoning_tokens': 0,\n",
       "  'rejected_prediction_tokens': 0},\n",
       " 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.__dict__\n",
    "response.response_metadata['token_usage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78a636e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Xuyuanyuan! It's great to meet you. How can I assist you today? Whether you have questions, need information, or just want to chat, I'm here to help!\n"
     ]
    }
   ],
   "source": [
    "res = conv.predict(input=\"my name is xuyuanyuan\")\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1da506c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 multiplied by 28 equals 1,624. If you have any more math questions or anything else you'd like to discuss, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "res = conv.predict(input=\"what is 58*28\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04e78c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Xuyuanyuan! If there's anything else you'd like to know or talk about, just let me know.\n"
     ]
    }
   ],
   "source": [
    "res = conv.predict(input=\"what is my name\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e024531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='my name is xuyuanyuan', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Hello Xuyuanyuan! It's great to meet you. How can I assist you today? Whether you have questions, need information, or just want to chat, I'm here to help!\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what is 58*28', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"58 multiplied by 28 equals 1,624. If you have any more math questions or anything else you'd like to discuss, feel free to ask!\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what is my name', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Your name is Xuyuanyuan! If there's anything else you'd like to know or talk about, just let me know.\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c5aa88",
   "metadata": {},
   "source": [
    "### custom memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71720a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_utils import create_conversation_chain_with_custom_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79afe9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 窗口记忆 (只记住最后3条消息)\n",
    "conv_window = create_conversation_chain_with_custom_memory(\"window\", k=3)\n",
    "\n",
    "# 2. Token限制记忆 (最多1000个token)\n",
    "conv_token = create_conversation_chain_with_custom_memory(\"token_buffer\", max_token_limit=1000)\n",
    "\n",
    "# 3. 总结记忆 (自动总结旧对话)\n",
    "conv_summary = create_conversation_chain_with_custom_memory(\"summary\")\n",
    "\n",
    "# 4. 总结+缓冲区记忆\n",
    "conv_summary_buffer = create_conversation_chain_with_custom_memory(\n",
    "    \"summary_buffer\", \n",
    "    max_token_limit=500\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0ae5997",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = conv_token.predict(input=\"What do you remember?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "333325dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = conv_summary.predict(input=\"what is my name!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dad1309c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have access to personal information like your name. If you'd like to share it, I'd be happy to address you by it!\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01aa5dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = conv_summary_buffer.predict(input=\"Hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82049e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello there! It's great to chat with you. How's your day going so far? If there's anything specific you'd like to talk about, whether it's technology, history, or even the latest trends, feel free to ask!\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bfdd42",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
