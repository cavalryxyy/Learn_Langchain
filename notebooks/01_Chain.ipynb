{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebcd1a14",
   "metadata": {},
   "source": [
    "## chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdaa186f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding connection: connected\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_utils import get_llm, get_conversation_chain, get_memory, MODEL_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8b2475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the configured LLM\n",
    "llm = get_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a410319",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the capital of {country}?\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5dfe117",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c28ef175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"country\": \"France\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08330748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my last update, there is no recognized country or region named \"Adhiash.\" It's possible that it might be a fictional place or a newly established region that hasn't been widely recognized or documented. If you have more context or details, I might be able to help further!\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"country\": \"Adhiash\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "063071c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of the United States is Washington, D.C.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"country\": \"USA\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb4c242",
   "metadata": {},
   "source": [
    "### sequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b89f134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "392cf3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rb/ms13cwjn2c5by6p4br_crkv80000gn/T/ipykernel_20445/2710489488.py:6: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  ideas_chain = LLMChain(llm=llm, prompt=ideas_template)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Generate ideas\n",
    "ideas_template = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Generate 3 short ideas about: {topic}\"\n",
    ")\n",
    "ideas_chain = LLMChain(llm=llm, prompt=ideas_template)\n",
    "\n",
    "# Step 2: Evaluate ideas\n",
    "evaluate_template = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=\"Pick the best idea from: {text}\"\n",
    ")\n",
    "evaluate_chain = LLMChain(llm=llm, prompt=evaluate_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f6af145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequential chain\n",
    "chain = SimpleSequentialChain(\n",
    "    chains=[ideas_chain, evaluate_chain],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efc59ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rb/ms13cwjn2c5by6p4br_crkv80000gn/T/ipykernel_20445/3924481326.py:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = chain.run(\"renewable energy\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m1. **Community Solar Gardens**: Develop small-scale solar farms in local neighborhoods that allow residents to purchase or lease solar panels. This initiative can democratize access to renewable energy, reduce electricity costs, and promote community engagement in sustainable practices. By sharing the benefits of solar energy, communities can collectively reduce their carbon footprint and foster a sense of environmental stewardship.\n",
      "\n",
      "2. **Wind-Powered Urban Infrastructure**: Integrate small wind turbines into urban infrastructure, such as streetlights, bus stops, and building rooftops. These micro-turbines can harness wind energy to power public amenities, reduce reliance on the grid, and provide a visible commitment to sustainability. This approach not only generates clean energy but also raises public awareness about renewable technologies and their potential applications in everyday life.\n",
      "\n",
      "3. **Renewable Energy Education Programs**: Launch educational initiatives in schools and universities focused on renewable energy technologies and their impact on the environment. These programs can include hands-on workshops, field trips to renewable energy sites, and collaborations with industry experts. By educating the next generation about the importance and potential of renewable energy, we can inspire future leaders to innovate and advocate for sustainable solutions in their communities and beyond.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mChoosing the best idea depends on the specific goals and context of the community or organization considering these options. However, if we focus on broad impact and long-term benefits, **Renewable Energy Education Programs** might be the most compelling choice.\n",
      "\n",
      "Here's why:\n",
      "\n",
      "1. **Long-term Impact**: Education has the power to shape future generations. By instilling knowledge and passion for renewable energy in students, we can cultivate a generation of informed citizens and leaders who prioritize sustainability.\n",
      "\n",
      "2. **Broad Reach**: Educational programs can reach a wide audience, from young students to university attendees, creating widespread awareness and understanding of renewable energy technologies.\n",
      "\n",
      "3. **Innovation and Advocacy**: Educated individuals are more likely to innovate and advocate for renewable energy solutions, potentially leading to new technologies and policies that further advance sustainability goals.\n",
      "\n",
      "4. **Community Engagement**: These programs can foster community involvement through workshops, field trips, and collaborations, creating a network of individuals committed to environmental stewardship.\n",
      "\n",
      "5. **Adaptability**: Education programs can be tailored to different age groups, regions, and educational institutions, making them versatile and adaptable to various needs and contexts.\n",
      "\n",
      "While all three ideas have merit, focusing on education can create a foundational shift in attitudes and behaviors towards renewable energy, leading to sustained and widespread change.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Use the chain\n",
    "result = chain.run(\"renewable energy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34b6faa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': None,\n",
       " 'memory': None,\n",
       " 'callbacks': None,\n",
       " 'verbose': True,\n",
       " 'tags': None,\n",
       " 'metadata': None,\n",
       " 'callback_manager': None,\n",
       " 'chains': [LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Generate 3 short ideas about: {topic}'), llm=AzureChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7fc1f40cc9d0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7fc1f40cf520>, root_client=<openai.lib.azure.AzureOpenAI object at 0x7fc1f11d8b50>, root_async_client=<openai.lib.azure.AsyncAzureOpenAI object at 0x7fc1f40cca00>, model_name='DevGPT4o', temperature=0.2, model_kwargs={}, openai_api_key=SecretStr('**********'), top_p=0.9, disabled_params={'parallel_tool_calls': None}, azure_endpoint='https://azswcdevbktchatgpt.openai.azure.com/', deployment_name='DevGPT4o', openai_api_version='2024-02-01', openai_api_type='azure'), output_parser=StrOutputParser(), llm_kwargs={}),\n",
       "  LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='Pick the best idea from: {text}'), llm=AzureChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7fc1f40cc9d0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7fc1f40cf520>, root_client=<openai.lib.azure.AzureOpenAI object at 0x7fc1f11d8b50>, root_async_client=<openai.lib.azure.AsyncAzureOpenAI object at 0x7fc1f40cca00>, model_name='DevGPT4o', temperature=0.2, model_kwargs={}, openai_api_key=SecretStr('**********'), top_p=0.9, disabled_params={'parallel_tool_calls': None}, azure_endpoint='https://azswcdevbktchatgpt.openai.azure.com/', deployment_name='DevGPT4o', openai_api_version='2024-02-01', openai_api_type='azure'), output_parser=StrOutputParser(), llm_kwargs={})],\n",
       " 'strip_outputs': False,\n",
       " 'input_key': 'input',\n",
       " 'output_key': 'output'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e63047",
   "metadata": {},
   "source": [
    "1. name: None\n",
    "Purpose: The name of the chain for identification\n",
    "Current Value: None (not set)\n",
    "Usage: Useful for debugging and logging when you have multiple chains\n",
    "2. memory: None\n",
    "Purpose: Memory component to store conversation history\n",
    "Current Value: None (no memory attached)\n",
    "Usage: Unlike ConversationChain, SimpleSequentialChain doesn't use memory by default\n",
    "3. callbacks: None\n",
    "Purpose: Callback functions for monitoring chain execution\n",
    "Current Value: None (no callbacks set)\n",
    "Usage: For logging, monitoring, or custom actions during chain execution\n",
    "4. verbose: True\n",
    "Purpose: Controls whether to show detailed output during execution\n",
    "Current Value: True (will show step-by-step execution)\n",
    "Usage: When True, you'll see each step's input/output\n",
    "5. tags: None\n",
    "Purpose: Tags for categorizing or filtering chains\n",
    "Current Value: None (no tags set)\n",
    "Usage: For organization and filtering in LangChain applications\n",
    "6. metadata: None\n",
    "Purpose: Additional metadata about the chain\n",
    "Current Value: None (no metadata set)\n",
    "Usage: For storing custom information about the chain\n",
    "7. callback_manager: None\n",
    "Purpose: Manages callback execution during chain runs\n",
    "Current Value: None (no callback manager)\n",
    "Usage: Coordinates multiple callbacks during execution\n",
    "8. chains: [LLMChain, LLMChain]\n",
    "Purpose: The actual chains that will be executed sequentially\n",
    "Current Value: Array with 2 LLMChain objects\n",
    "Usage: These are the steps that will run in order\n",
    "9. strip_outputs: False\n",
    "Purpose: Whether to strip whitespace from outputs\n",
    "Current Value: False (keep original formatting)\n",
    "Usage: When True, removes extra spaces/newlines\n",
    "10. input_key: 'input'\n",
    "Purpose: The key name for the input variable\n",
    "Current Value: 'input'\n",
    "Usage: When you call chain.run(\"text\"), it becomes {\"input\": \"text\"}\n",
    "11. output_key: 'output'\n",
    "Purpose: The key name for the final output\n",
    "Current Value: 'output'\n",
    "Usage: The final result is stored under this key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1fcd08",
   "metadata": {},
   "source": [
    "![image](/image/sequential_chain.png)\n",
    "\n",
    "\n",
    "![image](/image/router_chain.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
